% TODOs abhacken
% ADD Figures


\subsection{Reverse Engineering} \label{subsec:reverse-engineering}
    \subsubsection{Graph-Based Mapping Inference} \label{subsubsec:graph-based-mapping-inference}
        Building on the timing-channel primitive introduced in [One Bit Flips, One Cloud Flops], a novel 
        graph-based algorithm is employed to determine the memory mapping at runtime. 
        This approach models each bit in a physical address as a node in a graph and establishes 
        relationships between nodes based on measured memory access latencies. By exploiting the fact 
        that specific latency patterns emerge when addresses differ in particular bit positions, the method 
        enables the automatic and accurate detection of row bits, column bits, and bank bits.
        \\
        The core idea is implemented using a kernel module, named \texttt{latency.c} which reverse-engineers the physical-to-DRAM 
        address mapping by measuring access latencies \texttt{L(i,j)} between pairs of physical addresses that differ 
        in bits \texttt{i} and \texttt{j}. Large access latencies occur only when the two addresses reside in different rows 
        within the same bank, which allows the identification of row, column, and bank bits. On ARMv8 systems, 
        \texttt{latency.c} specifically focuses on locating the second-lowest row bit by systematically measuring the 
        latency between addresses that differ in exactly two bits and inferring which bit positions correspond 
        to row differences [118].
        \\
        The program output reports the time required to access two physical addresses that differ in two 
        bit positions. Each measurement is represented in the form \texttt{L(i,j):T}, where \texttt{T} denotes the measured 
        access time when the addresses differ in bit \texttt{i} and bit \texttt{j}. In the special case \texttt{i=j}, the addresses 
        differ in only a single bit. The key observation exploited by the analysis is that high latency 
        values occur exclusively when two addresses are located in different rows of the same bank, which 
        provides a distinguishing feature for identifying row, column, bank bits.
        \\
        % TODO: Aufzeigen was portiert wurde
        % \\
        The workflow involves porting, building and executing the tool [118]. The results are stored in 
        the \texttt{latency.log} file using the corresponding Python script which analyzes all bit positions. 
        The three bits exhibiting the highest average latency deviations are identified. 
        The analysis reveals that bits \texttt{12}, \texttt{13}, and \texttt{14} show the highest average latencies, with average 
        values of \texttt{299.25}, \texttt{298.41}, and \texttt{299.03} cycles, respectively.
        \\
        Despite these results, a problem arises from the fact that the observed latency deviations are 
        relatively small and do not demonstrate a significant difference. Despite this limited magnitude 
        of deviation, the resulting mapping remains consistent across multiple measurements. This 
        consistency aligns with findings from related work, particularly the [DRAM MaUT] mapping, as well 
        [Memory Aware DOS] mapping. However, due to the lack of pronounced 
        latency differences, these observations alone were insufficient, and consequently additional methods 
        were explored.

    \subsubsection{Algebraic Mapping Inference} \label{subsubsec:algebraic-mapping-inference}
        An alternative approach to physical-to-DRAM mapping inference is based on algebraic techniques 
        described in [99]. As outlined in the Methods section of the targeted approach, the Knock-Knock 
        method treats identifying parity masks as a linear algebra problem. This technique 
        directly targets the physical-to-DRAM mapping and enables the recovery of bank and row functions 
        without relying on iterative function checks. Instead, it computes the nullspace of conflicting 
        address sets.
        \\
        A major advantage of this tool is that it is a platform-agnostic design. It supports a wide range of 
        architectures, including x86\_64, ARMv8, and POWER9/10, which makes it suitable for all 
        test devices used in this work.
        \\
        The workflow requires activation of the \gls{pmu} via a kernel module.
        However, both the automatic and manual workflows failed to 
        recover any valid mapping. In all cases, the execution terminated with the warning “Threshold 
        quality check failed: Valley between peaks not pronounced enough.” Multiple mitigation attempts 
        were undertaken, including manual threshold selection, parameter tuning for noisy systems, and 
        high-precision measurement runs. Nevertheless, all attempts resulted in an insufficient number 
        of coherent conflict samples, which caused the derivation of bank masks to abort and the row mask 
        analysis to be skipped entirely.
        \\
        This limitation is closely related to the employed closed-page policy. Even the authors of [99] 
        reported that they were unable to retrieve any part of the mapping on a Raspberry Pi 4, as the 
        observed latency distribution consisted of a single peak indicative of a closed-page policy. 
        The same behavior was observed not only on the tested Raspberry Pi 4 but also consistently 
        across all Raspberry Pi 5 devices examined in this work. Further details and implications of 
        this issue are discussed in \hyperref[sec:discussion-and-limitations]{Discussion and Limitations}.

    \subsubsection{Row Hit, Row Conflict Distinction} \label{subsubsec:row-hit-row-conflict-distinction}
        Distinguishing row hits from row conflicts is a fundamental requirement for reverse engineering 
        \gls{dram} address mappings, because access latency directly reflects the internal organization of 
        banks and rows. By correlating timing differences with chosen address pairs, one can infer which 
        physical address bits select the bank and which select the row, without vendor documentation.
        However, based on the issues encountered in the previous part - most notably the insufficiently 
        pronounced valley between latency peaks - it remains 
        unclear whether a reliable distinction between row hits and row conflicts is feasible in practice.
        \\
        To further investigate this problem, an approach was designed to explicitly analyze the distinction 
        between row hits and row conflicts. This approach builds directly on observations from DRAMA and 
        similar prior work. Since access latency reflects the internal structure of banks and rows, 
        measuring timing differences between address pairs can reveal which physical address bits are 
        responsible for bank selection and which correspond to row selection, without relying on proprietary 
        information. Three types of access patterns are considered. 
        \\
        \textbf{Bank Miss}: both addresses are located in different banks, which results in low access times.
        \\
        \textbf{Row Hit}: both addresses reside in the same bank and row, also leading to low access times. 
        \\
        \textbf{Row Conflict}: both addresses are in the same bank but different rows, which 
        results in high access times.
        \\
        Assuming a system with \texttt{N} banks and \texttt{R} rows per bank, the probability \texttt{P} of a bank miss is given by 
        \[
        P_\text{Bank Miss} = 1 - \frac{1}{N}
        \]
        The probability of a row hit is
        \[
        P_\text{Row Hit} = \frac{1}{N} \cdot \frac{1}{R}
        \]
        while the probability of a row conflict is 
        \[
        P_\text{Row Conflict} = \frac{1}{N} \cdot \left(1 - \frac{1}{R}\right)
        \]

        Under these assumptions, two peaks are expected to become visible in the latency distribution. The 
        left peak corresponds to low access times and consists of bank misses and row hits, while the 
        right peak corresponds to high access times and consists of row conflicts [23, 73].
        \\
        To accurately distinguish between row hits and row conflicts in \gls{cpu}, it is essential to measure memory 
        access latencies while eliminating the influence of \gls{cpu} caches. This is achieved by isolating \gls{cpu} from 
        cache effects, which includes pinning the \gls{cpu} to a single core and repeatedly accessing pairs of randomly 
        selected addresses, identified through pagemap. Between each access, cache flush instructions 
        such as \texttt{DC CIVAC} are executed, and each address pair is probed for approximately 100.000 iterations. The 
        access latencies between these addresses are recorded, and after averaging across multiple measurements, 
        the results are consolidated into a single .log file. From this consolidated data, histograms representing 
        the distribution of row hits and row conflicts are generated, which helps reduce measurement noise.
        \\
        The measurement workflow can be implemented at different temporal resolutions. In the low-resolution 
        approach, as demonstrated in \texttt{bank-timing-probe.c}, the POSIX function \texttt{clock\_gettime()} is used to record 
        the elapsed time between events with nanosecond precision. However, the limited temporal resolution 
        of \texttt{clock\_gettime()} makes it unreliable for distinguishing the short latency differences between row hits 
        and row conflicts (see \hyperref[fig:lowRes]{Figure~\ref{fig:lowRes}}). 
        \begin{figure}[htbp]
            \centering
            \frame{\includegraphics[width=\linewidth]{img/lowRes.pdf}}
            \caption{Low Resolution with POSIX function \texttt{clock\_gettime()}}
            \label{fig:lowRes}
        \end{figure}
        To address this limitation, a high-resolution method, exemplified in 
        \texttt{rowhitconflict.c}, employs the \gls{pmccntr} instead of \texttt{clock\_gettime()}, allowing for finer measurement 
        resolution.
        \\
        Once latency data is collected, statistical analysis is performed to distinguish row hits from row 
        conflicts reliably. This analysis involves evaluating the latency distributions, determining thresholds, 
        and performing statistical validation, including computation of means, variances, confidence intervals, 
        and t-tests. The methodology leverages prior insights from [73, 99].
        \\
        A key step is identifying a reliable latency threshold that separates row hits from row conflicts. This 
        is achieved by collecting thousands of latency samples and constructing a smoothed histogram. The main 
        peak corresponding to row hits and the high-latency peak corresponding to row conflicts are identified, 
        and the threshold is set at the "left foot" of the high-latency peak. The threshold is further validated 
        by analyzing the peak distance and valley depth; if validation fails, a fallback threshold is applied. 
        This threshold is then used to classify memory accesses as row hits or row conflicts.
        \\
        For statistical validation, the latency samples are divided into row hit and row conflict groups according 
        to the threshold index.
        The results including mean, variance, confidence intervals, and the statistical significance 
        of the separation, are printed to ensure that the distinction between row hits and row conflicts is 
        statistically robust.

    \subsubsection{Bank Function Derivation} \label{subsubsec:bank-function-derivation}
        The DRAMA approach [73, 116, 159] derives \gls{dram} address mappings by grouping physical addresses 
        into \gls{dram} sets based on access-time differences caused by row hits, row conflicts, and bank 
        conflicts. From these sets, the tool infers the \gls{dram} address mapping by identifying XOR combinations 
        of physical address bits that consistently characterize the sets.
        \\
        DRAMA has previously been demonstrated to work on several ARM-based platforms, including ARMv7 
        systems with LPDDR2 and LPDDR3 memory [73] and ARMv8-A systems with LPDDR3 and LPDDR4 [83] memory [73, 159]. 
        These prior results provide proof that DRAMA can be ported to ARM architectures. Several challenges were 
        encountered during the ARM port. 
        \\
        First, the original DRAMA implementation
        relied on x86-specific instructions such as \texttt{RDTSC} and \texttt{CLFLUSH}, which are unavailable on ARM. To 
        address this, these functions were implemented using \texttt{PMCCNTR\_EL0} for 
        precise timing, and a \texttt{flush\_cache\_line()} function with a selection for one of eight ARM cache maintenance options, similar 
        to [118], was added to replace \texttt{CLFLUSH}. The \texttt{-march=armv8-a} compiler flag was used to ensure optimized 
        ARM code generation.
        \\
        A second challenge concerned measurement stability. The original DRAMA code measured each memory 
        access only once, which made the results susceptible to noise. To improve robustness, repeated 
        measurements were introduced by defining multiple runs of the entire measurement process. For each 
        run, memory mapping and random address pools are initialized, access times are measured across 
        all candidate addresses, and observed XOR combinations are accumulated. After all runs, the 
        observed combinations are aggregated, sorted, and saved to \texttt{combinations.dat}, thereby increasing 
        statistical confidence and reducing the influence of outliers.
        \\
        A third challenge involved result visualization. The original DRAMA code only printed XOR functions 
        and masks to the terminal, without any automated post-processing or visualization. To address this, 
        all detected XOR and non-XOR combinations are counted in \texttt{measure.cpp} and written to \texttt{combinations.dat}. 
        A Python script, \texttt{plot.py}, reads this file, separates XOR and non-XOR functions, sorts bit combinations 
        numerically, plots the counts as a bar chart with distinct visual encodings, and saves the resulting 
        figure with a filename derived from the host system. The Makefile integrates this workflow by executing 
        the measurement with \gls{cpu} pinning and automatically invoking \texttt{plot.py}, enabling reproducible and 
        device-independent visual analysis of \gls{dram} bank bit combinations.
    
        % Bit Mask Check
        As a final step, a bit mask check is used to verify a given physical-address-to-bank mapping using 
        configurable bit masks. Bank address bits are defined either as single physical address bits or as 
        XOR combinations of bits. A configurable fraction of system memory is allocated using \texttt{mmap}, and 
        virtual-to-physical address translation is resolved via pagemap. For each physical address, the 
        bank index is computed according to the specified bit mask mapping, and addresses belonging to 
        the same bank are grouped into lists. The number of physical addresses per bank list is then 
        output as a consistency check.
        \\
        % TODO: Was sind den jetzt die Results
        The results of this method strictly reflect the assumed bit-mask mapping provided as input. 
        Consequently, the approach allows only a plausibility and internal-consistency check of bank 
        assignments and does not guarantee that the derived mapping corresponds to the actual hardware 
        bank mapping.
